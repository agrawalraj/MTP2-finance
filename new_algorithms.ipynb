{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import linear_shrinkage\n",
    "import Util\n",
    "from Util import evaluate_curret, get_invest_period\n",
    "from os.path import join\n",
    "from generating_MTP import generate_mat as generate_MTP2\n",
    "import os\n",
    "import time\n",
    "import sklearn.covariance\n",
    "import pickle\n",
    "from collections import namedtuple, defaultdict\n",
    "from subprocess import Popen\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_loaded_data = Util.load_data()\n",
    "ret, ret_nonan, univ, tradeidx, dates = util_loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For saving to pastRets (pastRet and KTcov) and outRets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('./pastRets')\n",
    "assert os.path.exists('./outRets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_past_information(T, N, util_loaded_data, save_KT = True):\n",
    "    ret, ret_nonan, univ, tradeidx, dates = util_loaded_data\n",
    "    pastRets = []\n",
    "    KT_covs = []\n",
    "    \n",
    "    KT_time = 0\n",
    "    for h in range(len(univ)):\n",
    "        print(h, end = ' ')\n",
    "        \n",
    "        pastRet = Util.get_past_period(h, T, N, univ, tradeidx, ret)\n",
    "        pastRetFileName = \"pastRets/{}_{}_{}_pastRet.pkl\".format(T, N, h)\n",
    "        with open(pastRetFileName, 'wb') as f:\n",
    "            pickle.dump(pastRet, f)\n",
    "        pastRets.append(pastRet)\n",
    "        \n",
    "        if save_KT:\n",
    "            #start = time.time()\n",
    "            KT_cov = Util.kendall_cov(pastRet)\n",
    "            KT_cov_file_name =  \"pastRets/{}_{}_{}_KTcov.pkl\".format(T, N, h)\n",
    "            with open(KT_cov_file_name, 'wb') as f:\n",
    "                pickle.dump(KT_cov, f)\n",
    "            KT_covs.append(KT_cov)\n",
    "            end = time.time()\n",
    "            #print(end-start)\n",
    "    \n",
    "    with open(\"pastRets/{}_{}_pastRets.pkl\".format(T,N), 'wb') as f:\n",
    "        pickle.dump(pastRets, f)\n",
    "\n",
    "    if save_KT:\n",
    "        with open(\"pastRets/{}_{}_KTcovs.pkl\".format(T,N), 'wb') as f:\n",
    "            pickle.dump(KT_covs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for old purposes\n",
    "# for T in [25, 50, 100, 200, 500, 1260]:\n",
    "#     for N in [25, 50, 100, 200, 500, 1000]:\n",
    "#         save_past_information(T, N, util_loaded_data, save_KT = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for one-off\n",
    "# save_past_information(800,200, util_loaded_data, save_KT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for saving KT covs in parallel\n",
    "def save_KT_cov(h):\n",
    "    KT_cov_file_name =  \"pastRets/{}_{}_{}_KTcov.pkl\".format(T, N, h)\n",
    "    print(h)\n",
    "    if h == 0:\n",
    "        print(\"N={}, T={}\".format(N,T))\n",
    "    start = time.time()\n",
    "    ret, ret_nonan, univ, tradeidx, dates = util_loaded_data\n",
    "    pastRet = Util.get_past_period(h, T, N, univ, tradeidx, ret)\n",
    "    KT_cov = Util.kendall_cov(pastRet)\n",
    "    KT_cov_file_name =  \"pastRets/{}_{}_{}_KTcov.pkl\".format(T, N, h)\n",
    "    with open(KT_cov_file_name, 'wb') as f:\n",
    "        pickle.dump(KT_cov, f)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "\n",
    "def consolidate_KT_cov(N,T):\n",
    "    KT_covs = []\n",
    "    for h in range(360):\n",
    "        fname = \"pastRets/{}_{}_{}_KTcov.pkl\".format(T, N, h)\n",
    "        with open(fname, 'rb') as f:\n",
    "            cov = pickle.load(f)\n",
    "            KT_covs.append(cov)\n",
    "    with open(\"pastRets/{}_{}_KTcovs.pkl\".format(T,N), 'wb') as f:\n",
    "            pickle.dump(KT_covs, f)\n",
    "\n",
    "for N, T in []:\n",
    "    pool = Pool(8)\n",
    "    pool.map(save_KT_cov,range(360))\n",
    "    consolidate_KT_cov(N,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outrets(N, util_loaded_data, P=1):\n",
    "    ret, ret_nonan, univ, tradeidx, dates = util_loaded_data\n",
    "    all_outrets = []\n",
    "    for h in range(360):\n",
    "        outret = get_invest_period(h, P, N, univ, tradeidx, ret)\n",
    "        all_outrets.append(outret)\n",
    "    with open('outRets/{}_outRets.pkl'.format(N), 'wb') as f:\n",
    "        pickle.dump(all_outrets, f)\n",
    "\n",
    "for N in []:#[25, 50, 100, 200, 500, 1000]:\n",
    "    save_outrets(N, util_loaded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After this point is the algorithms and experiments, above was just generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "from estimators import (MTP2_wrapper, MTP2_cov_wrapper,\n",
    "                        LRPS_wrapper,\n",
    "                        CLIME_wrapper, CLIME_cov_wrapper,\n",
    "                        old_LS_wrapper, LS_wrapper, NLS_wrapper,\n",
    "                        POET_wrapper, POET_5_wrapper,\n",
    "                        glasso_wrapper,\n",
    "                        get_AFM_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_methods = { #all time estimates for N = 100\n",
    "    'glasso': glasso_wrapper, #2 seconds\n",
    "    #'MTP2': MTP2_wrapper, #25 seconds\n",
    "    #'MTP2_cov': MTP2_cov_wrapper,\n",
    "    'CLIME': CLIME_wrapper,\n",
    "    #'CLIME_cov': CLIME_cov_wrapper\n",
    "    #'LS': LS_wrapper, #0.5 seconds\n",
    "    #'old_LS_cov': old_LS_cov_wrapper,\n",
    "    'old_LS': old_LS_wrapper,\n",
    "    'NLS':  NLS_wrapper, #5 seconds\n",
    "    'LRPS': LRPS_wrapper, #7 seconds\n",
    "    'AFM_NL': get_AFM_estimator(5, 'NLS', tradeidx), #4 seconds\n",
    "    'AFM_LS': get_AFM_estimator(5, 'LS', tradeidx), #0.5 seconds\n",
    "    'POET': POET_wrapper,\n",
    "    'POET_5': POET_5_wrapper,\n",
    "    #'AFM_POET': None,\n",
    "    #'equiweight': None,\n",
    "    #'POET': POET_wrapper\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIME b'[1] \"Loaded X\"\\n'\n",
      "b'[1] 0.3034854\\n'\n",
      "b'$`clime(X, lambda = lambda_opt, sigma = FALSE, standardize = FALSE, perturb =`\\n'\n",
      "b'<environment: 0x7f83cffd8118>\\n'\n",
      "b'\\n'\n",
      "b'$`solve(Sigma)`\\n'\n",
      "b'<environment: 0x7f83cffd71c8>\\n'\n",
      "b'\\n'\n",
      "b'$`solve.default(Sigma)`\\n'\n",
      "b'<environment: 0x7f83cffdaea8>\\n'\n",
      "b'\\n'\n",
      "b'attr(,\"error.message\")\\n'\n",
      "b'[1] \"Error in solve.default(Sigma) : \\\\n  system is computationally singular: reciprocal condition number = 1.85327e-20\\\\nCalls: clime -> solve -> solve.default\\\\n\"\\n'\n",
      "b'attr(,\"class\")\\n'\n",
      "b'[1] \"dump.frames\"\\n'\n",
      "b''\n",
      "1.0553810596466064\n",
      "old_LS 0.0066297054290771484\n",
      "NLS b'[1] \"Loaded X\"\\n'\n",
      "b'Estimating population eigenvalues...[1] \"Finished with NLS\"\\n'\n",
      "b''\n",
      "7.202436685562134\n",
      "LRPS b'[1] \"### Computing the path on the full dataset first ###\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 10.454342850051 Sparsity: 0 Rank of L: 1\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 5.23958317240809 Sparsity: 0 Rank of L: 1\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 2.62601219553922 Sparsity: 0.000606060606060606 Rank of L: 5\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 1.31612378775378 Sparsity: 0.00707070707070707 Rank of L: 16\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 0.659624440295365 Sparsity: 0.0343434343434343 Rank of L: 24\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 0.330595348464572 Sparsity: 0.078989898989899 Rank of L: 34\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 0.165690168147003 Sparsity: 0.132727272727273 Rank of L: 39\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 0.0830417970128339 Sparsity: 0.182626262626263 Rank of L: 42\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 0.0416194885202997 Sparsity: 0.256969696969697 Rank of L: 43\"\\n'\n",
      "b'[1] \"Fitting with gamma= 0.15  and lambda= 0.020859156316471 Sparsity: 0.492929292929293 Rank of L: 45\"\\n'\n",
      "b'[1] \"### Now performing  3  fold cross validation. ###\"\\n'\n",
      "b'[1] \"Lambda: 10.454342850051 X-Val Log-lik: 71.5877362892842 #Edges: 0\"\\n'\n",
      "b'[1] \"Lambda: 5.23958317240809 X-Val Log-lik: 66.0709557444539 #Edges: 0\"\\n'\n",
      "b'[1] \"Lambda: 2.62601219553922 X-Val Log-lik: 66.1053395581404 #Edges: 3\"\\n'\n",
      "b'[1] \"Lambda: 1.31612378775378 X-Val Log-lik: 76.5080149429387 #Edges: 35\"\\n'\n",
      "b'[1] \"Lambda: 0.659624440295365 X-Val Log-lik: 106.720240777499 #Edges: 170\"\\n'\n",
      "b'[1] \"Lambda: 0.330595348464572 X-Val Log-lik: 185.790471620594 #Edges: 391\"\\n'\n",
      "b'[1] \"Lambda: 0.165690168147003 X-Val Log-lik: 361.394723477185 #Edges: 657\"\\n'\n",
      "b'[1] \"Lambda: 0.0830417970128339 X-Val Log-lik: 711.398946437993 #Edges: 904\"\\n'\n"
     ]
    }
   ],
   "source": [
    "T = 50\n",
    "N = 100\n",
    "with open('pastRets/{}_{}_pastRets.pkl'.format(T,N), 'rb') as f:\n",
    "    pastRets = pickle.load(f)\n",
    "timing_dict = {}\n",
    "for method_name, m_func in all_methods.items():\n",
    "    assert 'cov' not in method_name, 'Timing is not supported for methods with cov'\n",
    "    if 'glasso' in method_name:\n",
    "        continue\n",
    "    h = 0\n",
    "    print(method_name, end = ' ')\n",
    "    args = []\n",
    "    start = time.time()\n",
    "    if 'AFM' in method_name:\n",
    "        args = [h]\n",
    "    cov = m_func(pastRets[h], *args)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    timing_dict[method_name] = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('glasso', 2.0269057750701904), ('CLIME', 7.494525909423828), ('old_LS', 0.12046098709106445), ('NLS', 3.5360469818115234), ('LRPS', 14.29485297203064), ('AFM_NL', 1.3973491191864014), ('AFM_LS', 0.15255999565124512), ('POET', 18.873387098312378), ('POET_5', 19.070396900177002)])\n",
      "Total hours:  66.96648573875427\n"
     ]
    }
   ],
   "source": [
    "print(timing_dict.items())\n",
    "print(\"Total hours: \", sum(timing_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(\"./pickle\")\n",
    "assert os.path.exists('./run_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with run_name=first_server_run and KT_or_not=False\n",
      "All methods are: dict_keys(['glasso', 'CLIME', 'old_LS', 'NLS', 'LRPS', 'AFM_NL', 'AFM_LS', 'POET', 'POET_5'])\n",
      "N, T list is: [(100, 50), (100, 100), (100, 200), (100, 400), (100, 1260), (200, 100), (200, 200), (200, 400), (200, 800), (200, 1260), (500, 250), (500, 500), (500, 1000), (500, 1260)]\n",
      "SKIP EXISTING IS TRUE!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0052d90d8f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SKIP EXISTING IS TRUE!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Save information?\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrun_info_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"run_info/{}.info\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skip_existing = True\n",
    "run_name = \"first_server_run\"\n",
    "KT_or_not = False\n",
    "N_T_list = [(100,50),(100,100),(100,200),(100,400),(100,1260),\n",
    "            (200,100),(200,200),(200,400), (200,800), (200, 1260),\n",
    "            (500,250), (500,500), (500,1000), (500,1260)]\n",
    "\n",
    "print(\"Running with run_name={} and KT_or_not={}\".format(run_name, KT_or_not))\n",
    "print(\"All methods are: \" + str(all_methods.keys()))\n",
    "print(\"N, T list is: {}\".format(N_T_list))\n",
    "if skip_existing:\n",
    "    print(\"SKIP EXISTING IS TRUE!\")\n",
    "\n",
    "if input(\"Save information?\") == \"Y\":\n",
    "\n",
    "    run_info_name = \"run_info/{}.info\".format(run_name)\n",
    "    run_info = {\n",
    "        'run_name': run_name,\n",
    "        'KT_or_not': KT_or_not,\n",
    "        'N_T_list': N_T_list,\n",
    "        'all_methods_keys': list(all_methods.keys())\n",
    "    }\n",
    "    if os.path.exists(run_info_name):\n",
    "        if input(\"Run info already exists, want to append?\") == 'Y':\n",
    "            with open(run_info_name, 'rb') as f:\n",
    "                old_run_info = pickle.load(f)\n",
    "            old_run_info['N_T_list'] = list(set(old_run_info['N_T_list'] + N_T_list))\n",
    "            all_methods_keys_list = list(all_methods.keys())\n",
    "            old_run_info['all_methods_keys'] = list(set(old_run_info['all_methods_keys'] + all_methods_keys_list))\n",
    "            run_info = old_run_info\n",
    "    with open(run_info_name, 'wb') as f:\n",
    "        pickle.dump(run_info, f)\n",
    "\n",
    "for N, T in N_T_list:\n",
    "    if not os.path.exists('pastRets/{}_{}_pastRets.pkl'.format(T,N)):\n",
    "        print(\"pastRets doesn't exist for N,T={},{}\".format(N,T))\n",
    "        save_past_information(T,N, util_loaded_data, save_KT=False)\n",
    "    if not os.path.exists('outRets/{}_outRets.pkl'.format(N)):\n",
    "        print(\"outRets doesn't exist for N={}\".format(N))\n",
    "        save_outrets(N, util_loaded_data, P=1)\n",
    "    \n",
    "for N, T in N_T_list:\n",
    "    with open('pastRets/{}_{}_pastRets.pkl'.format(T,N), 'rb') as f:\n",
    "        pastRets = pickle.load(f)\n",
    "        assert len(pastRets) == 360\n",
    "\n",
    "    if os.path.isfile('pastRets/{}_{}_KTcovs.pkl'.format(T,N)):\n",
    "        with open('pastRets/{}_{}_KTcovs.pkl'.format(T,N), 'rb') as f:\n",
    "            pastCovs = pickle.load(f)\n",
    "    else:\n",
    "        print(\"pastCovs doesn't exist for T={} N={}\".format(T,N))\n",
    "        pastCovs = []\n",
    "\n",
    "    with open('outRets/{}_outRets.pkl'.format(N), 'rb') as f:\n",
    "        outRets = pickle.load(f)\n",
    "        assert len(outRets) == 360\n",
    "\n",
    "    print(\"Loaded all relevant information\")\n",
    "\n",
    "    def get_covs_all_methods(h):\n",
    "        print(\"WORKING ON h={}\".format(h))\n",
    "        for method_name, method in all_methods.items():\n",
    "            print('Starting on {}'.format(method_name))\n",
    "            fname = 'pickle/{}_{}_{}_{}_{}_{}_covEst.pkl'.format(T, N, h, method_name, KT_or_not, run_name)\n",
    "            if skip_existing and os.path.exists(fname):\n",
    "                continue\n",
    "            #USING PASTCOVS\n",
    "            if 'cov' in method_name:\n",
    "                args = []\n",
    "                if 'LS' in method_name or 'CLIME' in method_name:\n",
    "                    #args is number of samples\n",
    "                    args = [T]\n",
    "                cov = method(cov=pastCovs[h], *args)\n",
    "            else:\n",
    "            #USING PASTRETS\n",
    "                args = []\n",
    "                if 'AFM' in method_name:\n",
    "                    args = [h]\n",
    "                cov = method(pastRets[h], *args)\n",
    "\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(cov, f)\n",
    "    \n",
    "    pool = Pool(8)\n",
    "    pool.map(get_covs_all_methods, range(360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
